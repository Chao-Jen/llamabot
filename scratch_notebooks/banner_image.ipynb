{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot.prompt_manager import prompt\n",
    "\n",
    "\n",
    "@prompt\n",
    "def banner_image_prompt(summary):\n",
    "    \"\"\"\n",
    "    As 'Banner Artist',\n",
    "    your role is to create banner images for blog posts in a watercolor style,\n",
    "    with a 16:4 aspect ratio and use of vivid colors.\n",
    "    You will focus on maximizing the use of imagery and symbols to represent ideas,\n",
    "    strictly avoiding any text or character symbols.\n",
    "    Ensure that there is no text in the banner image!\n",
    "    Your creations should be abstract or symbolic,\n",
    "    suitable for a wide range of blog topics.\n",
    "    When provided with vague or lacking details in a blog summary,\n",
    "    you should make creative assumptions to interpret\n",
    "    and visualize the content into an appealing banner image.\n",
    "    Ensure that the background of the banner image is white.\n",
    "    Ensure that there is no text in the banner image!\n",
    "\n",
    "    Given the following summary, please give me a banner image:\n",
    "\n",
    "    {{ summary }}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "from llamabot import ImageBot\n",
    "\n",
    "\n",
    "imgbot = ImageBot(model=\"dall-e-3\", size=\"1792x1024\")\n",
    "\n",
    "summary = \"\"\"\n",
    "In this blog post, I share how to resolve CUDA backend initialization issues when installing JAX with CUDA, specifically addressing outdated cuDNN versions. I detail a method using Conda environments to manage CUDA installations and set environment variables correctly, offering two solutions: configuring LD_LIBRARY_PATH through Conda's activate.d and deactivate.d scripts, or directly within a Python session using a .env file. Both approaches aim to ensure that JAX utilizes the correct CUDA libraries, but each has its tradeoffs regarding portability. Curious about which method might work best for your setup?\n",
    "\"\"\"\n",
    "\n",
    "url = imgbot(banner_image_prompt(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bot critic for the image to see if there is text or not.\n",
    "\n",
    "# First, wget the image and base64 encode it.\n",
    "import base64\n",
    "import requests\n",
    "\n",
    "response = requests.get(url)\n",
    "# Download the image, resize it, and then read it into memory and convert it ot base64 encoding.\n",
    "from PIL import Image\n",
    "\n",
    "image_file = Image.open(response.content)\n",
    "image_file = image_file.resize((256, 256))\n",
    "image_file.save(\"image.jpg\")\n",
    "with open(\"image.jpg\", \"wb\") as f:\n",
    "    image_file = f.read()\n",
    "\n",
    "encoded_string = base64.b64encode(image_file).decode(\"utf-8\")\n",
    "\n",
    "# Create a SimpleBot bot critic.\n",
    "from llamabot import SimpleBot\n",
    "\n",
    "bot_critic = SimpleBot(\n",
    "    \"You are a bot that critiques images if they contain text. If they contain text, respond with 'yes'. If they do not contain text, respond with 'no'.\",\n",
    "    model_name=\"gpt-4o\",\n",
    ")\n",
    "bot_critic(encoded_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
