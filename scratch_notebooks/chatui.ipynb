{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot import SimpleBot\n",
    "from llamabot.components.messages import HumanMessage\n",
    "\n",
    "bot = SimpleBot(\"You are a funny bot.\", stream=True)\n",
    "\n",
    "\n",
    "test_message = \"Hello bot, what's the weather like?\"\n",
    "messages = [bot.system_prompt, HumanMessage(content=test_message)]\n",
    "\n",
    "# Stream the response and print each chunk\n",
    "# response = bot.stream_response(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "from llamabot.bot.simplebot import _make_response\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "chat_feed = pn.chat.ChatFeed()\n",
    "\n",
    "\n",
    "async def simplebot_callback(contents, user, instance):\n",
    "    return bot.stream_response(messages=[HumanMessage(content=contents)])\n",
    "\n",
    "\n",
    "def even_or_odd(contents, user, instance):\n",
    "    if len(contents) % 2 == 0:\n",
    "        return \"Even number of characters.\"\n",
    "    return \"Odd number of characters.\"\n",
    "\n",
    "\n",
    "async def stream_message(contents, user, instance):\n",
    "    message = \"\"\n",
    "    for character in contents:\n",
    "        message += character\n",
    "        yield message\n",
    "\n",
    "\n",
    "chat_interface = pn.chat.ChatInterface(\n",
    "    callback=simplebot_callback, callback_exception=\"verbose\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot.bot.chatbot import ChatBot\n",
    "from llamabot.components.chatui import ChatUIMixin\n",
    "from llamabot.config import default_language_model\n",
    "\n",
    "\n",
    "class ChatBotUI(ChatBot, ChatUIMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        system_prompt: str,\n",
    "        session_name: str,\n",
    "        temperature=0.0,\n",
    "        model_name=default_language_model(),\n",
    "        stream=True,\n",
    "        response_budget=2_000,\n",
    "    ):\n",
    "        ChatBot.__init__(\n",
    "            self,\n",
    "            session_name=session_name,\n",
    "            system_prompt=system_prompt,\n",
    "            temperature=temperature,\n",
    "            model_name=model_name,\n",
    "            stream=stream,\n",
    "            response_budget=response_budget,\n",
    "        )\n",
    "        ChatUIMixin.__init__(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = ChatBotUI(\"you are a funny bot\", session_name=\"test\", stream=True)\n",
    "bot.servable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
