{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Chatbot\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-built index.json file from Dropbox\n",
    "import requests\n",
    "\n",
    "headers = {\"user-agent\": \"Wget/1.16 (linux-gnu)\"}  # <-- the key is here!\n",
    "r = requests.get(\n",
    "    \"https://www.dropbox.com/s/wrixlu7e3noi43q/Ma%20et%20al.%20-%202021%20-%20Machine-Directed%20Evolution%20of%20an%20Imine%20Reductase%20f.pdf?dl=0\",\n",
    "    stream=True,\n",
    "    headers=headers,\n",
    ")\n",
    "pdf_fname = \"/tmp/machine-directed-evolution.pdf\"\n",
    "with open(pdf_fname, \"wb\") as f:\n",
    "    for chunk in r.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot import QueryBot\n",
    "from pyprojroot import here\n",
    "\n",
    "# If you're prototyping with your own PDF, uncomment the following code and use it instead of the saved index path:\n",
    "bot = QueryBot(\n",
    "    \"You are a bot that reads a PDF book and responds to questions about that book.\",\n",
    "    doc_paths=[pdf_fname],\n",
    ")\n",
    "\n",
    "# bot = QueryBot(\n",
    "#     \"You are a bot that reads a PDF book and responds to questions about that book.\",\n",
    "#     saved_index_path=\"/tmp/dshiring.json\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"I'd like to use the workflow of this paper to educate colleagues. What are the main talking points I should use?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot import PromptRecorder\n",
    "\n",
    "recorder = PromptRecorder()\n",
    "\n",
    "with recorder:\n",
    "    bot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"My colleagues are interested in evolving another enzyme. However, they may be unaware of how machine learning approaches will help them there. Based on this paper, what can I highlight that might overcome their lack of knowledge?\"\n",
    "\n",
    "with recorder:\n",
    "    bot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What data from the paper helped show this point, 'Machine-directed evolution is an efficient strategy for enzyme engineering, as it can help navigate enzyme sequence space more effectively and reduce the number of enzyme variants to be measured en route to a desirable enzyme under realistic process conditions.'?\"\n",
    "\n",
    "with recorder:\n",
    "    bot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"How can I succinctly present the SGM vs. EPPCR results to my colleagues? Or in other words, how would Richard Feynman present these results?\"\n",
    "\n",
    "with recorder:\n",
    "    bot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorder.panel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the source nodes used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.source_nodes[prompt]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SimpleBot below should prove that we are indeed querying a book\n",
    "and not just relying on the LLM's training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot import SimpleBot\n",
    "\n",
    "\n",
    "sbot = SimpleBot(\"You are a bot that responds to human questions.\")\n",
    "sbot(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
