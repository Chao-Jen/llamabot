{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "# ChatBots in a Jupyter Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Let's see how to use the ChatBot class to enable you to chat with Mistral inside a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='9ab0746b-288b-4101-b50f-800b5a1ca650'>\n",
       "  <div id=\"e2782f86-edba-47ee-9cdb-071ba68e3aeb\" data-root-id=\"9ab0746b-288b-4101-b50f-800b5a1ca650\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"afe00cab-3892-4696-89a8-7ae14fa9fb39\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"9ab0746b-288b-4101-b50f-800b5a1ca650\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"01e07354-fbb6-4c5d-b623-adf688dd68c2\",\"attributes\":{\"plot_id\":\"9ab0746b-288b-4101-b50f-800b5a1ca650\",\"comm_id\":\"3b1d8c5eaf244de286a668a801aee257\",\"client_comm_id\":\"4f8b024b147e4171849e77bb4f0992c0\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"afe00cab-3892-4696-89a8-7ae14fa9fb39\",\"roots\":{\"9ab0746b-288b-4101-b50f-800b5a1ca650\":\"e2782f86-edba-47ee-9cdb-071ba68e3aeb\"},\"root_ids\":[\"9ab0746b-288b-4101-b50f-800b5a1ca650\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "9ab0746b-288b-4101-b50f-800b5a1ca650"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llamabot import ChatBot\n",
    "\n",
    "code_tester = ChatBot(\n",
    "    \"\"\"\n",
    "You are a Python quality assurance developer who delivers high quality unit tests for code.\n",
    "You write tests using PyTest and not the built-in unittest library.\n",
    "Write the tests using test functions and not using classes and class methods\n",
    "Here is the code to write tests against:\n",
    "\"\"\",\n",
    "    session_name=\"code-tested\",\n",
    "    model_name=\"mistral/mistral-medium\",\n",
    "    stream_target=\"stdout\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<litellm.utils.CustomStreamWrapper object at 0x1140c2cd0>\n",
      "Here are the tests for the ChatBot class using PyTest and test functions:\n",
      "```python\n",
      "import pytest\n",
      "from chatbot import ChatBot, SystemMessage, HumanMessage\n",
      "from openai_callback import ChatOpenAI\n",
      "\n",
      "def test_chatbot_init():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt)\n",
      "    assert len(chatbot.chat_history) == 2\n",
      "    assert isinstance(chatbot.chat_history[0], SystemMessage)\n",
      "    assert isinstance(chatbot.chat_history[1], SystemMessage)\n",
      "    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\n",
      "    assert chatbot.chat_history[1].content == system_prompt\n",
      "\n",
      "def test_chatbot_call():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt)\n",
      "    human_message = \"What is the weather like today?\"\n",
      "    response = chatbot(human_message)\n",
      "    assert len(chatbot.chat_history) == 4\n",
      "    assert isinstance(chatbot.chat_history[2], HumanMessage)\n",
      "    assert isinstance(chatbot.chat_history[3], ChatOpenAI.Response)\n",
      "    assert chatbot.chat_history[2].content == human_message\n",
      "    assert response == chatbot.chat_history[3]\n",
      "\n",
      "def test_chatbot_call_multiple_times():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt)\n",
      "    human_message1 = \"What is the weather like today?\"\n",
      "    human_message2 = \"What is the temperature outside?\"\n",
      "    chatbot(human_message1)\n",
      "    chatbot(human_message2)\n",
      "    assert len(chatbot.chat_history) == 6\n",
      "    assert isinstance(chatbot.chat_history[2], HumanMessage)\n",
      "    assert isinstance(chatbot.chat_history[3], ChatOpenAI.Response)\n",
      "    assert isinstance(chatbot.chat_history[4], HumanMessage)\n",
      "    assert isinstance(chatbot.chat_history[5], ChatOpenAI.Response)\n",
      "    assert chatbot.chat_history[2].content == human_message1\n",
      "    assert chatbot.chat_history[4].content == human_message2\n",
      "\n",
      "def test_chatbot_temperature():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt, temperature=0.5)\n",
      "    assert chatbot.model.temperature == 0.5\n",
      "\n",
      "def test_chatbot_model_name():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt, model_name=\"gpt-3.5-turbo\")\n",
      "    assert chatbot.model.model_name == \"gpt-3.5-turbo\"\n",
      "```\n",
      "Note that these tests assume that the `ChatOpenAI` class and its `Response` class are defined elsewhere in the codebase. Also, the tests do not actually call the OpenAI API, but rather assume that the `ChatOpenAI` class is a mock or stub that returns a canned response. If you want to test the actual API calls, you will need to set up a test environment with a valid API key and handle any rate limiting or other issues that may arise."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', role='assistant')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_tester(\n",
    "    '''\n",
    "class ChatBot:\n",
    "    \"\"\"Chat Bot that is primed with a system prompt, accepts a human message.\n",
    "\n",
    "    Automatic chat memory management happens.\n",
    "\n",
    "    h/t Andrew Giessel/GPT4 for the idea.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, system_prompt, temperature=0.0, model_name=\"gpt-4\"):\n",
    "        \"\"\"Initialize the ChatBot.\n",
    "\n",
    "        :param system_prompt: The system prompt to use.\n",
    "        :param temperature: The model temperature to use.\n",
    "            See https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature\n",
    "            for more information.\n",
    "        :param model_name: The name of the OpenAI model to use.\n",
    "        \"\"\"\n",
    "        self.model = ChatOpenAI(\n",
    "            model_name=model_name,\n",
    "            temperature=temperature,\n",
    "            streaming=True,\n",
    "            verbose=True,\n",
    "            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "        )\n",
    "        self.chat_history = [\n",
    "            SystemMessage(content=\"Always return Markdown-compatible text.\"),\n",
    "            SystemMessage(content=system_prompt),\n",
    "        ]\n",
    "\n",
    "    def __call__(self, human_message) -> Response:\n",
    "        \"\"\"Call the ChatBot.\n",
    "\n",
    "        :param human_message: The human message to use.\n",
    "        :return: The response to the human message, primed by the system prompt.\n",
    "        \"\"\"\n",
    "        self.chat_history.append(HumanMessage(content=human_message))\n",
    "        response = self.model(self.chat_history)\n",
    "        self.chat_history.append(response)\n",
    "        return response\n",
    "'''\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "As you can see, ChatBot keeps track of conversation memory/history automatically.\n",
    "We can even access any item in the conversation by looking at the conversation history."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "The `__repr__` of a chatbot will simply print out the entire history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Human]\n",
       "\n",
       "class ChatBot:\n",
       "    \"\"\"Chat Bot that is primed with a system prompt, accepts a human message.\n",
       "\n",
       "    Automatic chat memory management happens.\n",
       "\n",
       "    h/t Andrew Giessel/GPT4 for the idea.\n",
       "    \"\"\"\n",
       "\n",
       "    def __init__(self, system_prompt, temperature=0.0, model_name=\"gpt-4\"):\n",
       "        \"\"\"Initialize the ChatBot.\n",
       "\n",
       "        :param system_prompt: The system prompt to use.\n",
       "        :param temperature: The model temperature to use.\n",
       "            See https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature\n",
       "            for more information.\n",
       "        :param model_name: The name of the OpenAI model to use.\n",
       "        \"\"\"\n",
       "        self.model = ChatOpenAI(\n",
       "            model_name=model_name,\n",
       "            temperature=temperature,\n",
       "            streaming=True,\n",
       "            verbose=True,\n",
       "            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
       "        )\n",
       "        self.chat_history = [\n",
       "            SystemMessage(content=\"Always return Markdown-compatible text.\"),\n",
       "            SystemMessage(content=system_prompt),\n",
       "        ]\n",
       "\n",
       "    def __call__(self, human_message) -> Response:\n",
       "        \"\"\"Call the ChatBot.\n",
       "\n",
       "        :param human_message: The human message to use.\n",
       "        :return: The response to the human message, primed by the system prompt.\n",
       "        \"\"\"\n",
       "        self.chat_history.append(HumanMessage(content=human_message))\n",
       "        response = self.model(self.chat_history)\n",
       "        self.chat_history.append(response)\n",
       "        return response\n",
       "\n",
       "    def __repr__(self):\n",
       "        \"\"\"Return a string representation of the ChatBot.\n",
       "\n",
       "        :return: A string representation of the ChatBot.\n",
       "        \"\"\"\n",
       "        representation = \"\"\n",
       "\n",
       "        for message in self.chat_history:\n",
       "            if isinstance(message, SystemMessage):\n",
       "                prefix = \"[System]\n",
       "\"\n",
       "            elif isinstance(message, HumanMessage):\n",
       "                prefix = \"[Human]\n",
       "\"\n",
       "            elif isinstance(message, AIMessage):\n",
       "                prefix = \"[AI]\n",
       "\"\n",
       "\n",
       "            representation += f\"{prefix}{message.content}\" + \"\n",
       "\n",
       "\"\n",
       "        return representation\n",
       "\n",
       "    def panel(self, show: bool = True):\n",
       "        \"\"\"Create a Panel app that wraps a LlamaBot.\n",
       "\n",
       "        :param show: Whether to show the app.\n",
       "            If False, we return the Panel app directly.\n",
       "            If True, we call `.show()` on the app.\n",
       "        :return: The Panel app, either showed or directly.\n",
       "        \"\"\"\n",
       "\n",
       "        text_input = pn.widgets.TextAreaInput(placeholder=\"Start chatting...\")\n",
       "        chat_history = pn.Column(*[])\n",
       "        send_button = pn.widgets.Button(name=\"Send\", button_type=\"primary\")\n",
       "\n",
       "        def b(event):\n",
       "            \"\"\"Button click handler.\n",
       "\n",
       "            :param event: The button click event.\n",
       "            \"\"\"\n",
       "            chat_messages = []\n",
       "            for message in self.chat_history:\n",
       "                if isinstance(message, SystemMessage):\n",
       "                    pass\n",
       "                elif isinstance(message, HumanMessage):\n",
       "                    chat_markdown = pn.pane.Markdown(f\"Human: {message.content}\")\n",
       "                    chat_messages.append(chat_markdown)\n",
       "                elif isinstance(message, AIMessage):\n",
       "                    chat_markdown = pn.pane.Markdown(f\"Bot: {message.content}\")\n",
       "                    chat_messages.append(chat_markdown)\n",
       "\n",
       "            chat_messages.append(pn.pane.Markdown(f\"Human: {text_input.value}\"))\n",
       "            bot_reply = pn.pane.Markdown(\"Bot: \")\n",
       "            chat_messages.append(bot_reply)\n",
       "            chat_history.objects = chat_messages\n",
       "            markdown_handler = PanelMarkdownCallbackHandler(bot_reply)\n",
       "            self.model.callback_manager.set_handler(markdown_handler)\n",
       "            self(text_input.value)\n",
       "            text_input.value = \"\"\n",
       "\n",
       "        send_button.on_click(b)\n",
       "        input_pane = pn.Row(text_input, send_button)\n",
       "        output_pane = pn.Column(chat_history, scroll=True, height=500)\n",
       "\n",
       "        main = pn.Row(input_pane, output_pane)\n",
       "        app = pn.template.FastListTemplate(\n",
       "            site=\"ChatBot\",\n",
       "            title=\"ChatBot\",\n",
       "            main=main,\n",
       "            main_max_width=\"768px\",\n",
       "        )\n",
       "        if show:\n",
       "            return app.show()\n",
       "        return app\n",
       "\n",
       "\n",
       "\n",
       "[AI]\n",
       "Here are some tests for the ChatBot class using PyTest:\n",
       "```python\n",
       "import pytest\n",
       "from your_module import ChatBot, SystemMessage, HumanMessage\n",
       "\n",
       "def test_init():\n",
       "    system_prompt = \"You are a helpful assistant.\"\n",
       "    chatbot = ChatBot(system_prompt)\n",
       "    assert len(chatbot.chat_history) == 2\n",
       "    assert isinstance(chatbot.chat_history[0], SystemMessage)\n",
       "    assert isinstance(chatbot.chat_history[1], SystemMessage)\n",
       "    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\n",
       "    assert chatbot.chat_history[1].content == system_prompt\n",
       "\n",
       "def test_call():\n",
       "    system_prompt = \"You are a helpful assistant.\"\n",
       "    chatbot = ChatBot(system_prompt)\n",
       "    human_message = \"What's the weather like today?\"\n",
       "    response = chatbot(human_message)\n",
       "    assert len(chatbot.chat_history) == 4\n",
       "    assert isinstance(chatbot.chat_history[2], HumanMessage)\n",
       "    assert isinstance(chatbot.chat_history[3], response.__class__)\n",
       "    assert chatbot.chat_history[2].content == human_message\n",
       "\n",
       "def test_repr():\n",
       "    system_prompt = \"You are a helpful assistant.\"\n",
       "    chatbot = ChatBot(system_prompt)\n",
       "    human_message = \"What's the weather like today?\"\n",
       "    chatbot(human_message)\n",
       "    expected_repr = (\n",
       "        \"[System]\\n\"\n",
       "        \"Always return Markdown-compatible text.\\n\\n\"\n",
       "        \"[System]\\n\"\n",
       "        \"You are a helpful assistant.\\n\\n\"\n",
       "        \"[Human]\\n\"\n",
       "        \"What's the weather like today?\\n\\n\"\n",
       "        \"[AI]\\n\"\n",
       "    )\n",
       "    assert repr(chatbot) == expected_repr\n",
       "\n",
       "def test_panel():\n",
       "    system_prompt = \"You are a helpful assistant.\"\n",
       "    chatbot = ChatBot(system_prompt)\n",
       "    app = chatbot.panel()\n",
       "    assert isinstance(app, type(pn.template.FastListTemplate()))\n",
       "```\n",
       "Note that the `test_panel` function assumes that the `pn` module is available in the test environment. If it is not, you may need to install it or mock it out for testing purposes.\n",
       "\n",
       "Also note that the `test_call` function assumes that the `response` object has a `__class__` attribute that can be used to check its type. If this is not the case, you may need to modify the test to use a different method of checking the type of the response object.\n",
       "\n",
       "Finally, note that these tests are not exhaustive and may not cover all possible edge cases or error conditions. You may want to add additional tests to ensure that the `ChatBot` class is working correctly in all scenarios.\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_tester"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "On the other hand, accessing the `.messages` attribute of the ChatBot will give you access to all of the messages inside the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='\\nclass ChatBot:\\n    \"\"\"Chat Bot that is primed with a system prompt, accepts a human message.\\n\\n    Automatic chat memory management happens.\\n\\n    h/t Andrew Giessel/GPT4 for the idea.\\n    \"\"\"\\n\\n    def __init__(self, system_prompt, temperature=0.0, model_name=\"gpt-4\"):\\n        \"\"\"Initialize the ChatBot.\\n\\n        :param system_prompt: The system prompt to use.\\n        :param temperature: The model temperature to use.\\n            See https://platform.openai.com/docs/api-reference/completions/create#completions/create-temperature\\n            for more information.\\n        :param model_name: The name of the OpenAI model to use.\\n        \"\"\"\\n        self.model = ChatOpenAI(\\n            model_name=model_name,\\n            temperature=temperature,\\n            streaming=True,\\n            verbose=True,\\n            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\\n        )\\n        self.chat_history = [\\n            SystemMessage(content=\"Always return Markdown-compatible text.\"),\\n            SystemMessage(content=system_prompt),\\n        ]\\n\\n    def __call__(self, human_message) -> Response:\\n        \"\"\"Call the ChatBot.\\n\\n        :param human_message: The human message to use.\\n        :return: The response to the human message, primed by the system prompt.\\n        \"\"\"\\n        self.chat_history.append(HumanMessage(content=human_message))\\n        response = self.model(self.chat_history)\\n        self.chat_history.append(response)\\n        return response\\n\\n    def __repr__(self):\\n        \"\"\"Return a string representation of the ChatBot.\\n\\n        :return: A string representation of the ChatBot.\\n        \"\"\"\\n        representation = \"\"\\n\\n        for message in self.chat_history:\\n            if isinstance(message, SystemMessage):\\n                prefix = \"[System]\\n\"\\n            elif isinstance(message, HumanMessage):\\n                prefix = \"[Human]\\n\"\\n            elif isinstance(message, AIMessage):\\n                prefix = \"[AI]\\n\"\\n\\n            representation += f\"{prefix}{message.content}\" + \"\\n\\n\"\\n        return representation\\n\\n    def panel(self, show: bool = True):\\n        \"\"\"Create a Panel app that wraps a LlamaBot.\\n\\n        :param show: Whether to show the app.\\n            If False, we return the Panel app directly.\\n            If True, we call `.show()` on the app.\\n        :return: The Panel app, either showed or directly.\\n        \"\"\"\\n\\n        text_input = pn.widgets.TextAreaInput(placeholder=\"Start chatting...\")\\n        chat_history = pn.Column(*[])\\n        send_button = pn.widgets.Button(name=\"Send\", button_type=\"primary\")\\n\\n        def b(event):\\n            \"\"\"Button click handler.\\n\\n            :param event: The button click event.\\n            \"\"\"\\n            chat_messages = []\\n            for message in self.chat_history:\\n                if isinstance(message, SystemMessage):\\n                    pass\\n                elif isinstance(message, HumanMessage):\\n                    chat_markdown = pn.pane.Markdown(f\"Human: {message.content}\")\\n                    chat_messages.append(chat_markdown)\\n                elif isinstance(message, AIMessage):\\n                    chat_markdown = pn.pane.Markdown(f\"Bot: {message.content}\")\\n                    chat_messages.append(chat_markdown)\\n\\n            chat_messages.append(pn.pane.Markdown(f\"Human: {text_input.value}\"))\\n            bot_reply = pn.pane.Markdown(\"Bot: \")\\n            chat_messages.append(bot_reply)\\n            chat_history.objects = chat_messages\\n            markdown_handler = PanelMarkdownCallbackHandler(bot_reply)\\n            self.model.callback_manager.set_handler(markdown_handler)\\n            self(text_input.value)\\n            text_input.value = \"\"\\n\\n        send_button.on_click(b)\\n        input_pane = pn.Row(text_input, send_button)\\n        output_pane = pn.Column(chat_history, scroll=True, height=500)\\n\\n        main = pn.Row(input_pane, output_pane)\\n        app = pn.template.FastListTemplate(\\n            site=\"ChatBot\",\\n            title=\"ChatBot\",\\n            main=main,\\n            main_max_width=\"768px\",\\n        )\\n        if show:\\n            return app.show()\\n        return app\\n\\n', role='user'),\n",
       " AIMessage(content='Here are some tests for the ChatBot class using PyTest:\\n```python\\nimport pytest\\nfrom your_module import ChatBot, SystemMessage, HumanMessage\\n\\ndef test_init():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    assert len(chatbot.chat_history) == 2\\n    assert isinstance(chatbot.chat_history[0], SystemMessage)\\n    assert isinstance(chatbot.chat_history[1], SystemMessage)\\n    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\\n    assert chatbot.chat_history[1].content == system_prompt\\n\\ndef test_call():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    human_message = \"What\\'s the weather like today?\"\\n    response = chatbot(human_message)\\n    assert len(chatbot.chat_history) == 4\\n    assert isinstance(chatbot.chat_history[2], HumanMessage)\\n    assert isinstance(chatbot.chat_history[3], response.__class__)\\n    assert chatbot.chat_history[2].content == human_message\\n\\ndef test_repr():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    human_message = \"What\\'s the weather like today?\"\\n    chatbot(human_message)\\n    expected_repr = (\\n        \"[System]\\\\n\"\\n        \"Always return Markdown-compatible text.\\\\n\\\\n\"\\n        \"[System]\\\\n\"\\n        \"You are a helpful assistant.\\\\n\\\\n\"\\n        \"[Human]\\\\n\"\\n        \"What\\'s the weather like today?\\\\n\\\\n\"\\n        \"[AI]\\\\n\"\\n    )\\n    assert repr(chatbot) == expected_repr\\n\\ndef test_panel():\\n    system_prompt = \"You are a helpful assistant.\"\\n    chatbot = ChatBot(system_prompt)\\n    app = chatbot.panel()\\n    assert isinstance(app, type(pn.template.FastListTemplate()))\\n```\\nNote that the `test_panel` function assumes that the `pn` module is available in the test environment. If it is not, you may need to install it or mock it out for testing purposes.\\n\\nAlso note that the `test_call` function assumes that the `response` object has a `__class__` attribute that can be used to check its type. If this is not the case, you may need to modify the test to use a different method of checking the type of the response object.\\n\\nFinally, note that these tests are not exhaustive and may not cover all possible edge cases or error conditions. You may want to add additional tests to ensure that the `ChatBot` class is working correctly in all scenarios.', role='assistant')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_tester.messages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "You can even access any arbitrary message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some tests for the ChatBot class using PyTest:\n",
      "```python\n",
      "import pytest\n",
      "from your_module import ChatBot, SystemMessage, HumanMessage\n",
      "\n",
      "def test_init():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt)\n",
      "    assert len(chatbot.chat_history) == 2\n",
      "    assert isinstance(chatbot.chat_history[0], SystemMessage)\n",
      "    assert isinstance(chatbot.chat_history[1], SystemMessage)\n",
      "    assert chatbot.chat_history[0].content == \"Always return Markdown-compatible text.\"\n",
      "    assert chatbot.chat_history[1].content == system_prompt\n",
      "\n",
      "def test_call():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt)\n",
      "    human_message = \"What's the weather like today?\"\n",
      "    response = chatbot(human_message)\n",
      "    assert len(chatbot.chat_history) == 4\n",
      "    assert isinstance(chatbot.chat_history[2], HumanMessage)\n",
      "    assert isinstance(chatbot.chat_history[3], response.__class__)\n",
      "    assert chatbot.chat_history[2].content == human_message\n",
      "\n",
      "def test_repr():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt)\n",
      "    human_message = \"What's the weather like today?\"\n",
      "    chatbot(human_message)\n",
      "    expected_repr = (\n",
      "        \"[System]\\n\"\n",
      "        \"Always return Markdown-compatible text.\\n\\n\"\n",
      "        \"[System]\\n\"\n",
      "        \"You are a helpful assistant.\\n\\n\"\n",
      "        \"[Human]\\n\"\n",
      "        \"What's the weather like today?\\n\\n\"\n",
      "        \"[AI]\\n\"\n",
      "    )\n",
      "    assert repr(chatbot) == expected_repr\n",
      "\n",
      "def test_panel():\n",
      "    system_prompt = \"You are a helpful assistant.\"\n",
      "    chatbot = ChatBot(system_prompt)\n",
      "    app = chatbot.panel()\n",
      "    assert isinstance(app, type(pn.template.FastListTemplate()))\n",
      "```\n",
      "Note that the `test_panel` function assumes that the `pn` module is available in the test environment. If it is not, you may need to install it or mock it out for testing purposes.\n",
      "\n",
      "Also note that the `test_call` function assumes that the `response` object has a `__class__` attribute that can be used to check its type. If this is not the case, you may need to modify the test to use a different method of checking the type of the response object.\n",
      "\n",
      "Finally, note that these tests are not exhaustive and may not cover all possible edge cases or error conditions. You may want to add additional tests to ensure that the `ChatBot` class is working correctly in all scenarios.\n"
     ]
    }
   ],
   "source": [
    "print(code_tester.messages[-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
