{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "# LLaMaBot's `StructuredBot` in under 5 minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "When using LLMs, an ideal goal would be to \n",
    "pull structured data out of unstructured text. \n",
    "When the data is structured, \n",
    "we can then use it programmatically in later steps.\n",
    "\n",
    "In this example, we'll look at a small dataset of SciPy videos uploaded to YouTube. \n",
    "The videos are given a title and a description. \n",
    "We want to extract the name of the speaker giving the talk, \n",
    "and the topics the talk is about.\n",
    "We also want to be able to validate the data we've extracted \n",
    "not only matches the structured format we expect, \n",
    "but that it also meets some custom requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read video descriptions\n",
    "\n",
    "Firstly, let's look at the video descriptions file. \n",
    "It is stored as a JSON file.\n",
    "We can read it into pandas by using `pd.read_json`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>view_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0ALKGR0I5MA</th>\n",
       "      <td>Basic Sound Processing in Python | SciPy 2015 ...</td>\n",
       "      <td></td>\n",
       "      <td>261832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZB7BZMhfPgk</th>\n",
       "      <td>Introduction to Numerical Computing with NumPy...</td>\n",
       "      <td>NumPy provides Python with a powerful array pr...</td>\n",
       "      <td>208823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v5ijNXvlC5A</th>\n",
       "      <td>Modern Time Series Analysis | SciPy 2019 Tutor...</td>\n",
       "      <td>This tutorial will cover the newest and most s...</td>\n",
       "      <td>199372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tYYVSEHq-io</th>\n",
       "      <td>Getting Started with TensorFlow and Deep Learn...</td>\n",
       "      <td>A friendly introduction to Deep Learning, taug...</td>\n",
       "      <td>161483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xAoljeRJ3lU</th>\n",
       "      <td>A Better Default Colormap for Matplotlib | Sci...</td>\n",
       "      <td>Complete SciPy 2015 Talk &amp; Tutorial Playlist h...</td>\n",
       "      <td>160912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5rNu16O3YNE</th>\n",
       "      <td>Introduction to Data Processing in Python with...</td>\n",
       "      <td>This is a tutorial for beginners on using the ...</td>\n",
       "      <td>117260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JNfxr4BQrLk</th>\n",
       "      <td>Time Series Analysis with Python Intermediate ...</td>\n",
       "      <td>Tutorial materials for the Time Series Analysi...</td>\n",
       "      <td>113018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KhAUfqhLakw</th>\n",
       "      <td>Frequentism and Bayesianism: What's the Big De...</td>\n",
       "      <td></td>\n",
       "      <td>106990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtejJ3RCddE</th>\n",
       "      <td>NumPy Beginner | SciPy 2016 Tutorial | Alexand...</td>\n",
       "      <td>Materials for this tutorial may be found here:...</td>\n",
       "      <td>106043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nq6iPZVUxZU</th>\n",
       "      <td>UMAP Uniform Manifold Approximation and Projec...</td>\n",
       "      <td>This talk will present a new approach to dimen...</td>\n",
       "      <td>96781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          name  \\\n",
       "0ALKGR0I5MA  Basic Sound Processing in Python | SciPy 2015 ...   \n",
       "ZB7BZMhfPgk  Introduction to Numerical Computing with NumPy...   \n",
       "v5ijNXvlC5A  Modern Time Series Analysis | SciPy 2019 Tutor...   \n",
       "tYYVSEHq-io  Getting Started with TensorFlow and Deep Learn...   \n",
       "xAoljeRJ3lU  A Better Default Colormap for Matplotlib | Sci...   \n",
       "5rNu16O3YNE  Introduction to Data Processing in Python with...   \n",
       "JNfxr4BQrLk  Time Series Analysis with Python Intermediate ...   \n",
       "KhAUfqhLakw  Frequentism and Bayesianism: What's the Big De...   \n",
       "gtejJ3RCddE  NumPy Beginner | SciPy 2016 Tutorial | Alexand...   \n",
       "nq6iPZVUxZU  UMAP Uniform Manifold Approximation and Projec...   \n",
       "\n",
       "                                                   description  view_count  \n",
       "0ALKGR0I5MA                                                         261832  \n",
       "ZB7BZMhfPgk  NumPy provides Python with a powerful array pr...      208823  \n",
       "v5ijNXvlC5A  This tutorial will cover the newest and most s...      199372  \n",
       "tYYVSEHq-io  A friendly introduction to Deep Learning, taug...      161483  \n",
       "xAoljeRJ3lU  Complete SciPy 2015 Talk & Tutorial Playlist h...      160912  \n",
       "5rNu16O3YNE  This is a tutorial for beginners on using the ...      117260  \n",
       "JNfxr4BQrLk  Tutorial materials for the Time Series Analysi...      113018  \n",
       "KhAUfqhLakw                                                         106990  \n",
       "gtejJ3RCddE  Materials for this tutorial may be found here:...      106043  \n",
       "nq6iPZVUxZU  This talk will present a new approach to dimen...       96781  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in unstructured text data\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"../scipy_videos.json\", orient=\"index\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Let's now define a Pydantic schema for the data that we wish to extract from movie entry.\n",
    "This is doen by defining a BaseModel class and field validators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "\n",
    "class TopicExtract(BaseModel):\n",
    "    \"\"\"This object stores the name of the speaker presenting the video.\n",
    "\n",
    "    It also generates a list of topics\n",
    "    that best describe what this talk is about.\n",
    "    \"\"\"\n",
    "\n",
    "    speaker_name: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=(\n",
    "            \"The name of the speaker giving this talk. \"\n",
    "            \"If there is no speaker named, leave empty.\"\n",
    "        ),\n",
    "    )\n",
    "    topics: List[str] = Field(\n",
    "        description=(\n",
    "            \"A list of upto 5 topics that this text is about. \"\n",
    "            \"Each topic should be at most 1 or 2 word descriptions. \"\n",
    "            \"All lowercase.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    @field_validator(\"topics\")\n",
    "    def validate_num_topics(cls, topics):\n",
    "        # validate that the list of topics contains atleast 1, and no more than 5 topics\n",
    "        if len(topics) <= 0 or len(topics) > 5:\n",
    "            raise ValueError(\"The list of topics can be no more than 5 items\")\n",
    "        return topics\n",
    "\n",
    "    @field_validator(\"topics\")\n",
    "    def validate_num_topic_words(cls, topics):\n",
    "        # for each topic the model generated, ensure that the topic contains no more than 2 words\n",
    "        for topic in topics:\n",
    "            if len(topic.split()) > 2:\n",
    "                # make the validation message helpful to the LLM.\n",
    "                # Here we repeat which topic is failing validation, and remind it what it must do to pass the validation.\n",
    "                raise ValueError(\n",
    "                    f'The topic \"{topic}\" has too many words, A topic can contain AT MOST 2 words'\n",
    "                )\n",
    "        return topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize the PydanticBot and assign this model to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamabot import prompt, StructuredBot\n",
    "\n",
    "\n",
    "@prompt\n",
    "def topicbot_sysprompt() -> str:\n",
    "    \"\"\"You are an expert topic labeller.\n",
    "    You read a video title and description\n",
    "    and extract the speakers name and the topics the video is about.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Will use the OpenAI API by default, which requires an API key.\n",
    "# If you want to, you can change this to a local LLM (from Ollama)\n",
    "# by specifying, say, `model_name=\"ollama/mistral\"`.\n",
    "bot = StructuredBot(\n",
    "    system_prompt=topicbot_sysprompt(),\n",
    "    temperature=0,\n",
    "    pydantic_model=TopicExtract,\n",
    "    # model_name=\"ollama/mistral\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Now we can pass in our text, and extract the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"speaker_name\": \"Allen Downey\",\n",
      "  \"topics\": [\n",
      "    \"sound\",\n",
      "    \"processing\",\n",
      "    \"python\",\n",
      "    \"scipy\",\n",
      "    \"basic\"\n",
      "  ]\n",
      "}{\n",
      "  \"speaker_name\": \"Alex Chabot-Leclerc\",\n",
      "  \"topics\": [\n",
      "    \"numerical computing\",\n",
      "    \"NumPy\",\n",
      "    \"array processing\",\n",
      "    \"mathematical functions\",\n",
      "    \"matplotlib\"\n",
      "  ]\n",
      "}{\n",
      "  \"speaker_name\": \"Aileen Nielsen\",\n",
      "  \"topics\": [\n",
      "    \"time series analysis\",\n",
      "    \"bayesian methods\",\n",
      "    \"machine learning\",\n",
      "    \"deep learning\",\n",
      "    \"python implementations\"\n",
      "  ]\n",
      "}"
     ]
    }
   ],
   "source": [
    "video_extracts = []\n",
    "for index, video_row in df.iterrows():\n",
    "    video_text = f\"video title: {video_row['name']}\\nvideo description: {video_row['description']}\"\n",
    "\n",
    "    extract = bot(video_text)\n",
    "\n",
    "    video_extracts.append(extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect what the topics looked like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in video_extracts:\n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's pretty accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "keep_output": true,
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
