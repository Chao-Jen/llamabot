{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "keep_output": true,
    "ExecuteTime": {
     "end_time": "2024-07-14T03:59:01.634937Z",
     "start_time": "2024-07-14T03:59:01.527760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "# LLaMaBot's PydanticBot in under 5 minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "We want to be able to pull structured data out of unstructured text. We want to be able to validate the data we've extracted matches the structured format we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "keep_output": true,
    "ExecuteTime": {
     "end_time": "2024-07-14T03:59:01.733897Z",
     "start_time": "2024-07-14T03:59:01.635943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Large Language Models (LLMs) are having a moment now!\\nWe can interact with them programmatically in ...'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in unstructured text data\n",
    "\n",
    "with open(\"../blog_text.txt\", \"r+\", encoding=\"utf8\") as f:\n",
    "    blog_text = f.read()\n",
    "blog_text[0:100] + \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Using Pydantic, we can define a class and some validation rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "keep_output": true,
    "ExecuteTime": {
     "end_time": "2024-07-14T03:59:01.827830Z",
     "start_time": "2024-07-14T03:59:01.735016Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "class TopicExtract(BaseModel):\n",
    "    \"\"\" a list of topics that is contained in the given text \"\"\"\n",
    "    topics: List[str] = Field(\n",
    "        description=\"A list of upto 5 topics that this text is about. Each topic should be at most 1 or 2 word descriptions.\")\n",
    "\n",
    "    @field_validator('topics')\n",
    "    def validate_topics(cls, topics):\n",
    "        # validate that the list of topics contains atleast 1, and no more than 5 topics \n",
    "        if len(topics) <= 0 or len(topics) > 5:\n",
    "            raise ValueError('The list of topics can be no more than 5 items')\n",
    "\n",
    "        # for each topic the model generated, ensure that the topic contains no more than 2 words\n",
    "        for topic in topics:\n",
    "            if len(topic.split()) > 2:\n",
    "                raise ValueError('A topic can contain AT MOST 2 words')\n",
    "        return topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize the PydanticBot and assign this model to it."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from llamabot.prompt_manager import prompt\n",
    "from llamabot.bot.pydanticbot import PydanticBot\n",
    "\n",
    "\n",
    "@prompt\n",
    "def write_system_schema_prompt(schema):\n",
    "    \"\"\"You are an expert topic labeller.\n",
    "    You read text and extract the topics the text is about.\"\n",
    "    \n",
    "    Your task is to return the topics in a json object that matches the following json_schema:\n",
    "    ```{{ schema }}```\n",
    "\n",
    "    Only return an INSTANCE of the schema, do not return the schema itself.\n",
    "    \"\"\"\n",
    "\n",
    "bot = PydanticBot(\n",
    "    system_prompt=write_system_schema_prompt(TopicExtract.schema_json()),\n",
    "    session_name=\"session_name\",\n",
    "    model_name = \"ollama/llama3:latest\",\n",
    "    temperature=0,\n",
    "    stream_target=\"stdout\",\n",
    "    pydantic_model=TopicExtract\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-14T03:59:01.943597Z",
     "start_time": "2024-07-14T03:59:01.830143Z"
    }
   },
   "execution_count": 15
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Now we can pass in our text, and extract the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "keep_output": true,
    "ExecuteTime": {
     "end_time": "2024-07-14T03:59:17.446072Z",
     "start_time": "2024-07-14T03:59:01.945091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the output in JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"topics\": [\n",
      "        \"Large Language Models\",\n",
      "        \"APIs and Abstractions\",\n",
      "        \"Content Generation\",\n",
      "        \"Blog Writing\",\n",
      "        \"Automation\"\n",
      "   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m20:59:06 - LiteLLM:WARNING\u001B[0m: litellm_logging.py:1290 - Model=llama3:latest not found in completion cost map. Setting 'response_cost' to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ]\n",
      "}\n",
      "```I apologize for the mistake! Here's another attempt at extracting topics from the text, this time ensuring that each topic is a single phrase or at most 2 words:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"topics\": [\n",
      "        \"Large Language Models\",\n",
      "        \"OpenAI API\",\n",
      "        \"LangChain Abstractions\",\n",
      "        \"Content Generation\",\n",
      "        \"Blog Writing\"\n",
      "    ]\n",
      "}\n",
      "```"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m20:59:11 - LiteLLM:WARNING\u001B[0m: litellm_logging.py:1290 - Model=llama3:latest not found in completion cost map. Setting 'response_cost' to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the mistake! Here's another attempt at extracting topics from the text, this time ensuring that each topic is a single phrase or at most 2 words:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"topics\": [\n",
      "        \"Large Language\",\n",
      "        \"OpenAI API\",\n",
      "        \"Content Generation\",\n",
      "        \"Blog Writing\",\n",
      "        \"Automation\"\n",
      "    ]\n",
      "}\n",
      "```"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[92m20:59:17 - LiteLLM:WARNING\u001B[0m: litellm_logging.py:1290 - Model=llama3:latest not found in completion cost map. Setting 'response_cost' to None\n"
     ]
    }
   ],
   "source": [
    "unstructured_text = blog_text[0:1000]\n",
    "\n",
    "extract = bot(unstructured_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T03:59:17.538834Z",
     "start_time": "2024-07-14T03:59:17.450879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language\n",
      "OpenAI API\n",
      "Content Generation\n",
      "Blog Writing\n",
      "Automation\n"
     ]
    }
   ],
   "source": [
    "for topic in extract.topics:\n",
    "    print(topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "keep_output": true,
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
