{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "# LLaMaBot's SimpleBot in under 5 minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Let's say we have the text of a blog..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Automatically write awesome commit messages\\n\\nAs a data scientist, I work with Git.\\n\\nIf you're anyt...\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../../data/blog_text.txt\", \"r+\") as f:\n",
    "    blog_text = f.read()\n",
    "blog_text[0:100] + \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "And we'd like to create a function that takes in the text and gives us a draft LinkedIn post,\n",
    "complete with emojis,\n",
    "that is designed to entice others to read the blog post.\n",
    "LLaMaBot's `SimpleBot` lets us build that function easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "from llamabot import SimpleBot\n",
    "\n",
    "system_prompt = \"\"\"You are a LinkedIn post generator bot.\n",
    "A human will give you the text of a blog post that they've authored,\n",
    "and you will compose a LinkedIn post that advertises it.\n",
    "The post is intended to hook a reader into reading the blog post.\n",
    "The LinkedIn post should be written with one line per sentence.\n",
    "Each sentence should begin with an emoji appropriate to that sentence.\n",
    "The post should be written in professional English and in first-person tone for the human.\n",
    "\"\"\"\n",
    "\n",
    "linkedin = SimpleBot(\n",
    "    system_prompt=system_prompt,\n",
    "    stream_target=\"stdout\",  # this is the default!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that SimpleBot by default will always stream. \n",
    "All that you need to configure is where you want to stream to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "With `linkedin`, we can now pass in the blog text and - voila! - get back a draft LinkedIn post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Excited to share my latest blog post on crafting meaningful commit messages!\n",
      "üëÄ Are your commit messages lacking detail and clarity?\n",
      "üí° I've developed a CLI tool within `llamabot` that crafts commit messages according to the Conventional Commits specification.\n",
      "ü§ñ With an OpenAI API key, GPT-4-32k will write a detailed commit message for you.\n",
      "üìù Meaningful commit messages improve collaboration within development teams.\n",
      "üîç They also facilitate better project management and aid in debugging and issue resolution.\n",
      "üåü Interested in trying out `llamabot`? Install it by running `pip install llamabot` at the terminal!\n"
     ]
    }
   ],
   "source": [
    "linkedin_post = linkedin(blog_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Now, you can edit it to your hearts content! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up, we have streaming that is compatible with Panel's Chat interface,\n",
    "which expects the text to be returned in its entirety as it is being built up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_panel = SimpleBot(\n",
    "    system_prompt=system_prompt,\n",
    "    stream_target=\"panel\",  # this is the default!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_post = linkedin_panel(blog_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for post in linkedin_post:\n",
    "    print(post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we have streaming via the API. We return a generator that yields individual parts of text as they are being generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkedin_api = SimpleBot(\n",
    "    system_prompt=system_prompt,\n",
    "    stream_target=\"api\",  # this is the default!\n",
    ")\n",
    "\n",
    "linkedin_post = linkedin_api(blog_text)\n",
    "for post in linkedin_post:\n",
    "    print(post, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "keep_output": true,
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
