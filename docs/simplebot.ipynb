{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "# LLaMaBot's SimpleBot in under 5 minutes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Let's say we have the text of a blog..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Large Language Models (LLMs) are having a moment now!\\nWe can interact with them programmatically in ...'"
      ]
     },
     "execution_count": null,
     "metadata": {
      "keep_output": true
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./blog_text.txt\", \"r+\") as f:\n",
    "    blog_text = f.read()\n",
    "blog_text[0:100] + \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "And we'd like to create a function that takes in the text and gives us a draft LinkedIn post,\n",
    "complete with emojis,\n",
    "that is designed to entice others to read the blog post.\n",
    "LLaMaBot's `SimpleBot` lets us build that function easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [],
   "source": [
    "from llamabot import SimpleBot\n",
    "\n",
    "linkedin = SimpleBot(\"\"\"You are a LinkedIn post generator bot.\n",
    "A human will give you the text of a blog post that they've authored,\n",
    "and you will compose a LinkedIn post that advertises it.\n",
    "The post is intended to hook a reader into reading the blog post.\n",
    "The LinkedIn post should be written with one line per sentence.\n",
    "Each sentence should begin with an emoji appropriate to that sentence.\n",
    "The post should be written in professional English and in first-person tone for the human.\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "With `linkedin`, we can now pass in the blog text and - voila! - get back a draft LinkedIn post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "keep_output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Large Language Models (LLMs) put to the test! üß™\n",
      "\n",
      "üìö I compared OpenAI's API, LangChain, and LlamaIndex for generating a blog post summary and LinkedIn post. üñãÔ∏è\n",
      "\n",
      "üí° Find out which library offers the best developer experience and the highest ROI in human time! ‚è≥\n",
      "\n",
      "ü§ñ Can LLMs truly revolutionize our writing process? üìù\n",
      "\n",
      "üëâ Discover the results and insights on my latest blog post: [Comparing OpenAI's API, LangChain, and LlamaIndex for LLM Applications](<blog_post_link>) üåê\n"
     ]
    }
   ],
   "source": [
    "linkedin_post = linkedin(blog_text)\n",
    "print(linkedin_post.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "keep_output": true
   },
   "source": [
    "Now, you can edit it to your hearts content! :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamabot",
   "keep_output": true,
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
